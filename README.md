# WEBCRAWLER

A ideia nesse projeto era construir um webscraping que capturasse apartir de um link inicial outros links e mineirasse
mais e mais links, ele cumpre as especificacoes mas na aba de melhoria podera ver que ha muitas coisas ha serem feitas!


## Ambiente
pyhton 3.8.8
```bash
pip install -r requirements.txt

```
## Rodando localmente
```
1-Crie um clone do projeto localmente
2-Acesse o terminal na pasta do projeto
3-Rode o comando "scrapy crawl PegarLinks"
obs: como o projeto nao esta totalmente finalizado para parar 
a execucao utilize o comando "CRTL + C"
4-acesse o sqlitestudio abra o arquivo "bdCrawlerLinks", click na
tabela e depois e assim conseguira ver todos os links validos salvos

